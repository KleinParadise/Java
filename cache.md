### Why Need Cache
  - 关系型数据库原子性、一致性、隔离性和持久性架构复杂导致性能低
  - 高并发的查询会给数据库带来压力,导致数据库不稳定并且容易造成数据延迟
  - 局部性原理，80%的请求会落到20%热点数据上，在读多写少场景下，增加一层缓存非常有助提升系统吞吐量和健壮性

### Cache的三种模式
- Cache Aside 旁路缓存
  - 读写策略
    - 写入数据,更新DB,然后把key从缓存中移除,由DB驱动缓存数据更新
    - 读数据,先从缓存中获取数据。如果缓存中无数据,则从DB中获取数据并将数据写入缓存中 
  - 特点
    - 确保数据以DB结果为准，则可以大幅降低cache和DB中数据不一致的概率
  - 应用场景
    - 针对数据一致性要求较高或者缓存数据更新比较复杂的业务


- Read/Write Through读写穿透
  - 读写策略
    - 业务由存储服务代理,业务与存储逻辑分离
    - 存储服务收到业务应用的写请求时，会首先查cache，如果数据在cache中不存在，则只更新DB，如果数据在cache中存在，则先更新cache，然后更新DB
    - 存储服务收到读请求时，如果命中cache直接返回，否则先从DB加载，回种到cache后返回响应。
  - 特点
    - 存储服务封装了数据处理细节,开发者只关注业务本身,数据与业务耦合度低。有缓存数据才更新,内存使用率更高
  - 应用场景
    - 针对不常用的数据(如不活跃的用户),不加入缓存中直接更新DB返回即可。提高内存使用率


- Write Behind Caching异步缓存写入
  - 读写策略
    - 与读写穿透类似,业务由存储服务代理,业务与存储逻辑分离
    - 写入数据,只更新缓存,不直接更新 DB,而是改为异步批量的方式来更新DB
    - 存储服务收到读请求时，如果命中cache直接返回，否则先从DB加载，回种到cache后返回响应。
  - 特点
    - 数据存储的写性能最高,非常适合一些变更特别频繁的业务,特别是可以合并写请求的业务
    - 数据的一致性变差,甚至在一些极端场景下可能会丢失数据(异步回写DB)
  - 应用场景
    - 适合变更频率特别高，但对一致性要求不太高的业务，这样写操作可以异步批量写入DB，减小DB压力


### 分布缓存设计需要考量的点
  - 分布式算法(取模分布还是hash一致性分布)
    - 取模分布方案简单,对新增节点,删除节点,节点异常处理较差。hash一致性实现相对复杂但是能很好的处理新增节点,删除节点,节点异常的情况
  - 读写方式选择（client读写还是通过Proxy代理读写）
    - client读写性能最好,但是业务与数据耦合度高。Proxy代理读写性能较差,业务与数据耦合度低
  - 缓存迁移的方式(server自身迁移还是通过Proxy代理迁移)
    - 评估数据是否需要迁移以及需要迁移的成本


### 缓存架构部署需要考量的点
  - 核心,高并发访问的不同数据,需要拆分到独立的缓冲池中。访问量小,非核心的数据可以混存。
  - 海量数据需要考虑分层访问(业务获取数据分层),并且分担访问量,避免访问过载
  - 考虑如何跨idc更新缓存,消息队列还是数据库trigger
  - 考虑多个缓存组件混用,
  - 考虑对缓存管理,集群管理,运维监控



### 缓存架构设计需要考量的点
  - 数据读取方式。(全部读写or部分读写及变更)
  - kvSize size过大考虑拆分,不同结构的数据,也应该尽量避免放在一起
  - key的数量 如果key数量不大,考虑缓存所有的key。如果key数量巨大,考虑只缓存一部分。
  - 读写峰值的判断。如果峰值不大,考虑简单拆分到独立的Cache池;如果峰值过大考虑local-cache配合远程cache,远程cache内存再分层和分池处理。
  - 命中率,预留大容量,确保核心业务有高命中率。
  - key的过期策略(先进先出,时间戳等)
  - 平均缓存穿透加载时间,
    对于一些缓存穿透后，加载时间特别长或者需要复杂计算的数据，而且访问量还比较大的业务数据，要配置更多容量，维持更高的命中率，从而减少穿透到DB的概率，来确保整个系统的访问性能。
  - 缓存的可运维性(易扩展节点)
  - 缓存的安全性(考虑数据落地)

### 缓存清空的策略
  - 先进先出 最先缓存的最早清除,比较创建时间。在数据实效性要求场景下可选择该类策略，优先保障最新数据可用
  - LFU 根据元素的被使用次数判断，清除使用次数较少的元素释放空间。主要比较元素的hitCount（命中次数）。在保证高频数据有效性场景下，可选择这类策略。
  - LRU 根据元素最后一次被使用的时间戳，清除最远使用时间戳的元素释放空间。主要比较元素最后一次get使用时间。在热点数据场景下较适用，优先保证热点数据的有效性。
  - 随机清理
  - 根据关键字或者元素内容长短清理

### 缓存失效处理
  - 问题描述
    - 大量的key在一段时间内全部失效,给DB造成压力
  - 解决方案
    - 设置key过期时间 = base时间 + 随机时间 避免key在一段时间内全部过期

### 缓存穿透处理
  - 问题描述
    - 遭到攻击,大量访问DB中不存在的key,给DB造成压力
  - 解决方案
    - 1. 仍然记录这个key到缓存,给一个特殊的值。非法key过多设置key较短的过期时间,或者给非法key设置一个单独的缓存记录
    - 2. 加BloomFilter过滤器,访问key时候先查过滤器,如果过滤器中没有直接返回。(非法key数据不大10亿以下,否则占用太多内存)
      - BloomFilter算法
        - 分配内存做为bit数组,初始化为0,加入元素时采用k个相互独立的Hash函数计算，然后将元素Hash映射的K个位置全部设置为1。检测key时，仍然用这k个Hash函
          数计算出k个位置，如果位置全部为1，则表明key存在，否则不存在。

### 缓存雪崩处理
  - 问题描述
    - 缓存部分节点不可用,从而导致整个缓存节点不可用
      - 缓存不支持rehash导致的系统雪崩不可用,缓存节点失效,大量请求访问DB
      - 缓存支持rehash导致的缓存雪崩不可用,某种情况集中读写一两个节点导致这两个节点crash,然后rehash到其他节点,进而导致其他节点也过载crash
  - 解决方案
    - 1. DB设置读写开关,发现DB异常时候关闭读写,部分读DBfail返回,待缓存恢复再打开DB开关
    - 2. 缓存多个副本,部署在不同机架,miss后读取备份缓存,最后再访问DB
    - 3. 对缓存服务进行监控,出现情况关闭边缘业务,保证核心业务正常运行

### 缓存与DB数据一致性的四种策略
- 等待过期,不做干预
  - 策略
    - 使用redis的过期时间,mysql更新时,redis不做处理,等待缓存过期失效,再从mysql拉取缓
  - 优缺点
    - 原生接口,实现简单
    - 完全依赖过期时间,过期时间太短容易造成缓存频繁失效，过期太长容易导致数据较长时间不一致,不适合读取数据频繁的应用
- 删除缓存,重新加载
  - 策略
    - 有数据更新的时候直接更新DB,然后从缓存中删除数据
  - 优缺点
    - 实现简单,减少数据不一致延迟的时间
    - 在高并发场景，业务server需要和mysql、redis同时进行连接，这样是损耗双倍的连接资源，容易造成连接数过多的问题。同时也有缓存数据删除失败的问题
- 主动更新,信箱投递
  - 策略
    - 在更新mysql之后更新操作交给消息队列，由消息队列保证可靠性，此外再搭建一个消费服务订阅消息队列，来异步更新redis数据。
  - 优缺点
    - DB数据与缓存数据更新解耦,
    - 在延迟情况下,进入消息队列的数据顺序可能不一致,导致更新缓存数据错误
    - 引入消息队列业务更加复杂,同时也增加了连接数
- 订阅日志,触发更新
  - 策略
    - 搭建的消费服务作为mysql的一个slave，订阅mysql的binlog日志，解析日志内容，再更新到redis
  - 优缺点
    - 与业务解耦,并且无时序性问题
    - 需要搭建额外的监听服务,成本较大

### 并发竞争处理
  - 问题描述
    - 缓存过期,仍然有大量的访问
  - 解决方案
    - 1. 使用全局锁,当请求缓存miss之后,只有加全局锁的线程才可以去DB访问数据,其他线程等待,待从DB加入数据到缓存再让其他线程访问。
    - 2. 对缓存数据做多个备份,当主缓存的数据被删除了,还可以从其他备份中访问

### hotKey处理
  - 问题描述
    - 大量请求访问一个key,流量集中到一个缓冲机器,导致访问变慢卡顿
  - 解决方案
    - 1. 分析出热点Key
    - 2. 将热点key加入后缀分散到多个节点,客户端在访问的时候随机访问其中某个后缀的hotkey,将热key请求打散,避免访问一个节点过载

### BigKey处理
  - 问题描述
    - 数据过大,导致对该数据读写,加载超时的情况
  - 解决方案
    - 1.预先在缓存组件中分配出对应的内存,后面系统在运行时候,有足够的空间进行缓存。通过数据超过设置的阈值,对数据进行压缩
    - 2.扩展新的数据结构,在写入缓存之前先进行序列号,然后通过restore一次性写入
    - 3.将数据拆分,并设置较长的过期时间,同等淘汰情况下,尽量不淘汰bigkey

### hash一致性实现原理
  - 将数据和节点都放在hash环上面,数据按照顺时针缓存到离它最近的节点
  - 虚拟节点的作用,使节点在环上分布更加均匀,从而使数据在节点上面分布更加均匀,避免某个节点过载


